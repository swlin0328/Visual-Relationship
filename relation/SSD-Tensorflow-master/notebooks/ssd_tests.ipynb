{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim.python.slim import queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as mpcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import dataset_factory\n",
    "from nets import nets_factory\n",
    "from preprocessing import preprocessing_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some drawing routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colors_subselect(colors, num_classes=62):\n",
    "    dt = len(colors) // num_classes\n",
    "    sub_colors = []\n",
    "    for i in range(num_classes):\n",
    "        color = colors[i*dt]\n",
    "        if isinstance(color[0], float):\n",
    "            sub_colors.append([int(c * 255) for c in color])\n",
    "        else:\n",
    "            sub_colors.append([c for c in color])\n",
    "    return sub_colors\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"Draw a collection of lines on an image.\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "            \n",
    "def draw_rectangle(img, p1, p2, color=[255, 0, 0], thickness=2):\n",
    "    cv2.rectangle(img, p1[::-1], p2[::-1], color, thickness)\n",
    "    \n",
    "    \n",
    "def draw_bbox(img, bbox, shape, label, color=[255, 0, 0], thickness=2):\n",
    "    p1 = (int(bbox[0] * shape[0]), int(bbox[1] * shape[1]))\n",
    "    p2 = (int(bbox[2] * shape[0]), int(bbox[3] * shape[1]))\n",
    "    cv2.rectangle(img, p1[::-1], p2[::-1], color, thickness)\n",
    "    p1 = (p1[0]+15, p1[1])\n",
    "    cv2.putText(img, str(label), p1[::-1], cv2.FONT_HERSHEY_DUPLEX, 0.5, color, 1)\n",
    "\n",
    "\n",
    "def bboxes_draw_on_img(img, classes, scores, bboxes, colors, thickness=2):\n",
    "    shape = img.shape\n",
    "    for i in range(bboxes.shape[0]):\n",
    "        bbox = bboxes[i]\n",
    "        color = colors[classes[i]]\n",
    "        # Draw bounding box...\n",
    "        p1 = (int(bbox[0] * shape[0]), int(bbox[1] * shape[1]))\n",
    "        p2 = (int(bbox[2] * shape[0]), int(bbox[3] * shape[1]))\n",
    "        cv2.rectangle(img, p1[::-1], p2[::-1], color, thickness)\n",
    "        # Draw text...\n",
    "        s = '%s/%.3f' % (classes[i], scores[i])\n",
    "        p1 = (p1[0]-5, p1[1])\n",
    "        cv2.putText(img, s, p1[::-1], cv2.FONT_HERSHEY_DUPLEX, 0.4, color, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = colors_subselect(mpcm.plasma.colors, num_classes=63)\n",
    "colors_tableaus = [(255, 255, 255), (31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "                 (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "                 (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "                 (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "                 (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]\n",
    "colors_tableau = [color for idx in range(3) for color in colors_tableaus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pascal VOC dataset\n",
    "\n",
    "Check the Pascal VOC pipeline and associated TFRecords files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import pascalvoc_2007\n",
    "#from datasets import pascalvoc_2012\n",
    "\n",
    "DATASET_DIR = 'D:\\\\relation\\\\pic\\\\'\n",
    "SPLIT_NAME = 'train'\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Dataset provider loading data from the dataset.\n",
    "dataset = pascalvoc_2007.get_split(SPLIT_NAME, DATASET_DIR)\n",
    "provider = slim.dataset_data_provider.DatasetDataProvider(dataset, \n",
    "                                                          shuffle=False,\n",
    "#                                                           num_epochs=1,\n",
    "                                                          common_queue_capacity=2 * BATCH_SIZE,\n",
    "                                                          common_queue_min=BATCH_SIZE)\n",
    "[image, shape, bboxes, labels, relations] = provider.get(['image', 'shape', 'object/bbox', 'object/label', 'object/relation'])\n",
    "print('Dataset:', dataset.data_sources, '|', dataset.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem: image shape is not fully defined => random crop with deterministic size.\n",
    "xy = tf.random_uniform((2, ), minval=0, maxval=shape[0] // 3, dtype=tf.int64)\n",
    "image_crop = tf.slice(image, [0, 0, 0], [250, 250, 3])\n",
    "\n",
    "print('Original vs crop:', image.get_shape(), image_crop.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = tf.train.batch([image_crop], batch_size=BATCH_SIZE, num_threads=1, capacity=5 * BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with queues.QueueRunners(sess):\n",
    "# Start populating queues.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw groundtruth bounding boxes using TF routine.\n",
    "image_bboxes = tf.squeeze(tf.image.draw_bounding_boxes(tf.expand_dims(tf.to_float(image) / 255., 0), \n",
    "                                                       tf.expand_dims(bboxes, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Eval and display the image + bboxes.\n",
    "rimg, rshape, rbboxes, rlabels, relations = isess.run([image_bboxes, shape, bboxes, labels, relations])\n",
    "\n",
    "print('Image shape:', rshape)\n",
    "print('Bounding boxes:', rbboxes)\n",
    "print('Labels:', rlabels)\n",
    "print('Relations:', relations)\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "plt.imshow(rimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SSD-300 model using TFRecords pipeline\n",
    "\n",
    "Restore model and test it on some random images coming from Pascal TFRecords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets import ssd_vgg_300\n",
    "from nets import ssd_vgg_512\n",
    "from nets import ssd_common\n",
    "\n",
    "from preprocessing import ssd_vgg_preprocessing\n",
    "\n",
    "ckpt_filename = 'D:\\\\relation\\\\SSD-Tensorflow-master\\\\checkpoints\\\\ssd_300_vgg.ckpt'\n",
    "# ckpt_filename = '/media/paul/DataExt4/PascalVOC/training/ckpts/SSD_512x512_ft/ssd_512_vgg.ckpt'\n",
    "# ckpt_filename = '/home/paul/Development/Research/SSD-Tensorflow/logs/ssd_300_vgg_2/model.ckpt-148624'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SSD object.\n",
    "reuse = True if 'ssd' in locals() else None\n",
    "params = ssd_vgg_300.SSDNet.default_params\n",
    "ssd = ssd_vgg_300.SSDNet(params)\n",
    "\n",
    "# Image pre-processimg\n",
    "out_shape = ssd.params.img_shape\n",
    "image_pre, labels_pre, bboxes_pre, bbox_img = \\\n",
    "    ssd_vgg_preprocessing.preprocess_for_eval(image, labels, bboxes, out_shape, \n",
    "                                              resize=ssd_vgg_preprocessing.Resize.CENTRAL_CROP)\n",
    "image_4d = tf.expand_dims(image_pre, 0)\n",
    "\n",
    "# SSD construction.\n",
    "with slim.arg_scope(ssd.arg_scope(weight_decay=0.0005)):\n",
    "    predictions, localisations, logits, end_points = ssd.net(image_4d, is_training=True, reuse=reuse)\n",
    "    \n",
    "# SSD default anchor boxes.\n",
    "img_shape = out_shape\n",
    "layers_anchors = ssd.anchors(img_shape, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sorted(end_points.keys()):\n",
    "    print(k, end_points[k].get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets encoding.\n",
    "target_labels, target_localizations, target_scores = \\\n",
    "    ssd_common.tf_ssd_bboxes_encode(labels, bboxes_pre, layers_anchors, \n",
    "                                    num_classes=params.num_classes, no_annotation_label=params.no_annotation_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tf_extended import bboxes\n",
    "nms_threshold = 0.5\n",
    "\n",
    "# Output decoding.\n",
    "localisations = ssd.bboxes_decode(localisations, layers_anchors)\n",
    "tclasses, tscores, tbboxes = ssd_common.tf_ssd_bboxes_select_all_classes(predictions, localisations)\n",
    "tclasses, tscores, tbboxes = bboxes.bboxes_sort_all_classes(tclasses, tscores, tbboxes, top_k=400)\n",
    "#tclasses, tscores, tbboxes = bboxes.bboxes_fast_nms(tclasses, tscores, tbboxes, nms_threshold=0.3, num_classes=ssd.params.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Initialize variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "isess.run(init_op)\n",
    "# Restore SSD model.\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(isess, ckpt_filename)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimistic_restore(session, save_file):\n",
    "    reader = tf.train.NewCheckpointReader(save_file)\n",
    "    saved_shapes = reader.get_variable_to_shape_map()\n",
    "    var_names = sorted([(var.name, var.name.split(':')[0]) for var in tf.global_variables() \n",
    "                        if var.name.split(':')[0] in saved_shapes])\n",
    "    restore_vars = []\n",
    "    name2var = dict(zip(map(lambda x:x.name.split(':')[0], tf.global_variables()), tf.global_variables()))\n",
    "    with tf.variable_scope('', reuse=True):\n",
    "        for var_name, saved_var_name in var_names:\n",
    "            curr_var = name2var[saved_var_name]\n",
    "            var_shape = curr_var.get_shape().as_list()\n",
    "            if var_shape == saved_shapes[saved_var_name]:\n",
    "                restore_vars.append(curr_var)\n",
    "    return restore_vars\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "isess.run(init_op)\n",
    "restore_vars = optimistic_restore(isess, ckpt_filename)\n",
    "\n",
    "my_saver = tf.train.Saver(restore_vars)\n",
    "sv = tf.train.Supervisor(logdir=\"D:\\\\relation\", save_model_secs=3600, saver=my_saver)\n",
    "saver = sv.saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run model.\n",
    "[rimg, rpredictions, rlocalisations, rclasses, rscores, rbboxes, glabels, gbboxes, rbbox_img, rt_labels, rt_localizations, rt_scores] = \\\n",
    "    isess.run([image_4d, predictions, localisations, tclasses, tscores, tbboxes,\n",
    "               labels, bboxes_pre, bbox_img, \n",
    "               target_labels, target_localizations, target_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bboxes_select(classes, scores, bboxes, threshold=0.1):\n",
    "    \"\"\"Sort bounding boxes by decreasing order and keep only the top_k\n",
    "    \"\"\"\n",
    "    mask = scores > threshold\n",
    "    classes = classes[mask]\n",
    "    scores = scores[mask]\n",
    "    bboxes = bboxes[mask]\n",
    "    return classes, scores, bboxes\n",
    "\n",
    "print(rclasses, rscores)\n",
    "print(rscores.shape)\n",
    "\n",
    "rclasses, rscores, rbboxes = bboxes_select(rclasses, rscores, rbboxes, 0.02)\n",
    "# print(list(zip(rclasses, rscores)))\n",
    "# print(rbboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute classes and bboxes from the net outputs.\n",
    "# rclasses, rscores, rbboxes,_,_ = ssd_common.ssd_bboxes_select(rpredictions, rlocalisations, layers_anchors,\n",
    "#                                                                threshold=0.3, img_shape=img_shape, \n",
    "#                                                                num_classes=21, decode=True)\n",
    "# rbboxes = ssd_common.bboxes_clip(rbbox_img, rbboxes)\n",
    "# rclasses, rscores, rbboxes = ssd_common.bboxes_sort(rclasses, rscores, rbboxes, top_k=400, priority_inside=False)\n",
    "# rclasses, rscores, rbboxes = ssd_common.bboxes_nms(rclasses, rscores, rbboxes, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Draw bboxes\n",
    "img_bboxes = np.copy(ssd_vgg_preprocessing.np_image_unwhitened(rimg[0]))\n",
    "bboxes_draw_on_img(img_bboxes, rclasses, rscores, rbboxes, colors_tableau, thickness=1)\n",
    "# bboxes_draw_on_img(img_bboxes, glabels, np.zeros_like(glabels), gbboxes, colors_tableau, thickness=1)\n",
    "# bboxes_draw_on_img(img_bboxes, test_labels, test_scores, test_bboxes, colors_tableau, thickness=1)\n",
    "\n",
    "print('Labels / scores:', list(zip(rclasses, rscores)))\n",
    "print('Grountruth labels:', list(glabels))\n",
    "print(gbboxes)\n",
    "print(rbboxes)\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "plt.imshow(img_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_extended import bboxes\n",
    "\n",
    "isess.run(bboxes.bboxes_jaccard(gbboxes[0], rbboxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bboxes = []\n",
    "test_labels = []\n",
    "test_scores = []\n",
    "for i in range(0, 3):\n",
    "    yref, xref, href, wref = layers_anchors[i]\n",
    "    ymin = yref - href / 2.\n",
    "    xmin = xref - wref / 2.\n",
    "    ymax = yref + href / 2.\n",
    "    xmax = xref + wref / 2.\n",
    "    bb = np.stack([ymin, xmin, ymax, xmax], axis=-1)\n",
    "    \n",
    "    idx = yref.shape[0] // 2\n",
    "    idx = np.random.randint(yref.shape[0])\n",
    "#     print(bb[idx, idx].shape)\n",
    "    test_bboxes.append(bb[idx, idx])\n",
    "    test_labels.append(np.ones(href.shape, dtype=np.int64) * i)\n",
    "    test_scores.append(np.ones(href.shape))\n",
    "\n",
    "test_bboxes = np.concatenate(test_bboxes)\n",
    "test_labels = np.concatenate(test_labels)\n",
    "test_scores = np.concatenate(test_scores)\n",
    "\n",
    "print(test_bboxes.shape)\n",
    "print(test_labels.shape)\n",
    "print(test_scores.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_labels, rt_localizations, rt_scores\n",
    "for i in range(len(rt_labels)):\n",
    "    print(rt_labels[i].shape)\n",
    "    idxes = np.where(rt_labels[i] > 0)\n",
    "#     idxes = np.where(rt_scores[i] > 0.)\n",
    "    print(idxes)\n",
    "    print(rt_localizations[i][idxes])\n",
    "    print(list(zip(rt_labels[i][idxes], rt_scores[i][idxes])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize = (8,8))\n",
    "# plt.imshow(ssd_preprocessing.np_image_unwhitened(rimg[0]))\n",
    "# print('Ground truth labels: ', rlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request threads to stop. Just to avoid error messages\n",
    "# coord.request_stop()\n",
    "# coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PleaseStopHere;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SSD-300 model using sample images\n",
    "\n",
    "Restore model and test it on some sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input placeholder.\n",
    "net_shape = (300, 300)\n",
    "img_input = tf.placeholder(tf.uint8, shape=(None, None, 3))\n",
    "image_pre, labels_pre, bboxes_pre, bbox_img = ssd_preprocessing.preprocess_for_eval(\n",
    "    img_input, labels, None, net_shape, resize=ssd_preprocessing.Resize.PAD_AND_RESIZE)\n",
    "image_4d = tf.expand_dims(image_pre, 0)\n",
    "\n",
    "# Re-define the model\n",
    "reuse = True if 'ssd' in locals() else None\n",
    "with slim.arg_scope(ssd.arg_scope(weight_decay=0.0005)):\n",
    "    predictions, localisations, logits, end_points = ssd.net(image_4d, is_training=False, reuse=reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing routine.\n",
    "def process_image(img, select_threshold=0.5, nms_threshold=0.35, net_shape=(300, 300)):\n",
    "    # Run SSD network.\n",
    "    rimg, rpredictions, rlocalisations, rbbox_img = isess.run([image_4d, predictions, localisations, bbox_img],\n",
    "                                                              feed_dict={img_input: img})\n",
    "    # Compute classes and bboxes from the net outputs.\n",
    "    rclasses, rscores, rbboxes, rlayers, ridxes = ssd_common.ssd_bboxes_select(\n",
    "            rpredictions, rlocalisations, layers_anchors,\n",
    "            threshold=select_threshold, img_shape=net_shape, num_classes=21, decode=True)\n",
    "#     print(list(zip(classes, scores)))\n",
    "#     print(rlayers)\n",
    "#     print(ridxes)\n",
    "    \n",
    "    rbboxes = ssd_common.bboxes_clip(rbbox_img, rbboxes)\n",
    "    rclasses, rscores, rbboxes = ssd_common.bboxes_sort(rclasses, rscores, rbboxes, \n",
    "                                                        top_k=400, priority_inside=True, margin=0.0)\n",
    "    rclasses, rscores, rbboxes = ssd_common.bboxes_nms(rclasses, rscores, rbboxes, threshold=nms_threshold)\n",
    "    # Resize bboxes to original image shape.\n",
    "    rbboxes = ssd_common.bboxes_resize(rbbox_img, rbboxes)\n",
    "    return rclasses, rscores, rbboxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test on demo images.\n",
    "path = '../demo/'\n",
    "image_names = sorted(os.listdir(path))\n",
    "img = mpimg.imread(path + image_names[-3])\n",
    "\n",
    "rclasses, rscores, rbboxes =  process_image(img)\n",
    "\n",
    "# Draw results.\n",
    "img_bboxes = np.copy(img)\n",
    "bboxes_draw_on_img(img_bboxes, rclasses, rscores, rbboxes, colors_tableau, thickness=2)\n",
    "\n",
    "fig = plt.figure(figsize = (12, 12))\n",
    "plt.imshow(img_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes = np.where(inside)\n",
    "rscores[idxes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some TensorFlow tests..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[5.0, 2], [5.0, 2]])\n",
    "b = tf.constant([5.0, 2])\n",
    "c = a * b\n",
    "d = tf.nn.l2_normalize(a, dim=1)\n",
    "# We can just use 'c.eval()' without passing 'sess'\n",
    "print(d.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few tests on Caffe model files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import caffe\n",
    "import numpy as np\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "caffe_filename = '/media/paul/DataExt4/PascalVOC/training/ckpts/SSD_300x300_ft/ssd_300_vgg.caffemodel'\n",
    "caffe_filename = '/media/paul/DataExt4/PascalVOC/training/ckpts/SSD_512x512_ft/ssd_512_vgg.caffemodel'\n",
    "\n",
    "caffemodel_params = caffe_pb2.NetParameter()\n",
    "caffemodel_str = open(caffe_filename, 'rb').read()\n",
    "caffemodel_params.ParseFromString(caffemodel_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layers = caffemodel_params.layer\n",
    "names = [(i, l.name, l.type, l.blobs[0].shape.dim if len(l.blobs) else 0) for i, l in enumerate(layers)]\n",
    "pprint(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "layer = layers[idx]\n",
    "print(layer.type)\n",
    "a = np.array(layer.blobs[0].data)\n",
    "s = layer.blobs[0].shape.dim\n",
    "print(s, 38*38)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets import caffe_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc = caffe_scope.CaffeScope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "d[csc.conv_biases_init] = 0\n",
    "d[csc.conv_biases_init] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dim = 300\n",
    "mbox_source_layers = ['conv4_3', 'fc7', 'conv6_2', 'conv7_2', 'conv8_2', 'conv9_2']\n",
    "min_ratio = 15\n",
    "max_ratio = 90\n",
    "step = int(math.floor((max_ratio - min_ratio) / (len(mbox_source_layers) - 2)))\n",
    "min_sizes = []\n",
    "max_sizes = []\n",
    "for ratio in range(min_ratio, max_ratio + 1, step):\n",
    "    min_sizes.append(min_dim * ratio / 100.)\n",
    "    max_sizes.append(min_dim * (ratio + step) / 100.)\n",
    "min_sizes = [min_dim * 7 / 100.] + min_sizes\n",
    "max_sizes = [min_dim * 15 / 100.] + max_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_sizes)\n",
    "print(max_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_shapes=[(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [8, 16, 32, 64, 100, 300]\n",
    "offset = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(steps)):\n",
    "    print((feat_shapes[i][0] - offset) * steps[i] / 300, (feat_shapes[i][0] - offset) / feat_shapes[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dim = 512\n",
    "# conv4_3 ==> 64 x 64\n",
    "# fc7 ==> 32 x 32\n",
    "# conv6_2 ==> 16 x 16\n",
    "# conv7_2 ==> 8 x 8\n",
    "# conv8_2 ==> 4 x 4\n",
    "# conv9_2 ==> 2 x 2\n",
    "# conv10_2 ==> 1 x 1\n",
    "mbox_source_layers = ['conv4_3', 'fc7', 'conv6_2', 'conv7_2', 'conv8_2', 'conv9_2', 'conv10_2']\n",
    "# in percent %\n",
    "min_ratio = 10\n",
    "max_ratio = 90\n",
    "step = int(math.floor((max_ratio - min_ratio) / (len(mbox_source_layers) - 2)))\n",
    "min_sizes = []\n",
    "max_sizes = []\n",
    "for ratio in range(min_ratio, max_ratio + 1, step):\n",
    "    min_sizes.append(min_dim * ratio / 100.)\n",
    "    max_sizes.append(min_dim * (ratio + step) / 100.)\n",
    "min_sizes = [min_dim * 4 / 100.] + min_sizes\n",
    "max_sizes = [min_dim * 10 / 100.] + max_sizes\n",
    "steps = [8, 16, 32, 64, 128, 256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_sizes)\n",
    "print(max_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(list(zip(min_sizes, max_sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
